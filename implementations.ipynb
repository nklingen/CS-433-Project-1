{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "implementations.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nklingen/CS-433-Project-1/blob/master/implementations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S9i9NKottsGH",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SMH95nqZs22G",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfUTXbA4Wiyw",
        "colab_type": "text"
      },
      "source": [
        "# **1. Least Squares Gradient Descent**\n",
        "Linear regression using gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "44RSzhP1t8_v",
        "colab": {}
      },
      "source": [
        "def least_squares_GD(y, tx, initial_w, max_iters, gamma): \n",
        "        ws = [initial_w]\n",
        "        losses = []\n",
        "        w = initial_w\n",
        "    \n",
        "        for n_iter in range(max_iters):\n",
        "            # ***************************************************\n",
        "            # compute gradient and loss\n",
        "            gradient = compute_gradient(y, tx, w)\n",
        "            loss = compute_loss(y, tx, w)\n",
        "            # ***************************************************\n",
        "            # update w by gradient\n",
        "            w = w - gamma*gradient\n",
        "            # ***************************************************\n",
        "            # store w and loss\n",
        "            ws.append(w)\n",
        "            losses.append(loss)\n",
        "            \n",
        "        return ws[-1], losses[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXLpV5RCWl2n",
        "colab_type": "text"
      },
      "source": [
        "# **2. Least Squares Stochastic Gradient Descent**\n",
        "Linear regression using stochastic gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gqMQctqJueGt",
        "colab": {}
      },
      "source": [
        "def least_squares_SGD(y, tx, initial_w, max_iters, gamma): \n",
        "  return (w, loss) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTVYJq_nWoFk",
        "colab_type": "text"
      },
      "source": [
        "# **3. Least Squares**\n",
        "Least squares regression using normal equations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W9PWr4-Tuh3v",
        "colab": {}
      },
      "source": [
        "def least_squares(y, tx):\n",
        "    w = np.linalg.solve(np.dot(tx.T,tx), np.dot(tx.T,y))\n",
        "    MSE = compute_loss(y, tx, w)\n",
        "    return w, MSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBflVp0FWpCf",
        "colab_type": "text"
      },
      "source": [
        "# **4. Ridge Regression**\n",
        "Ridge regression using normal equations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rG2j5WYXukiZ",
        "colab": {}
      },
      "source": [
        "def ridge_regression(y, tx, lambda_):\n",
        "    a = (1/len(y))*(np.dot(tx.T,tx)) + 2*(lambda_*np.identity(tx.shape[1]))\n",
        "    b = (1/len(y))*np.dot(tx.T,y)\n",
        "    w = np.linalg.solve(a,b)\n",
        "    MSE = compute_loss(y, tx, w)\n",
        "    return w, MSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE6g9RoTWuOf",
        "colab_type": "text"
      },
      "source": [
        "# **5. Logistic Regression**\n",
        "Logistic regression using gradient descent or SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B63ld585urMs",
        "colab": {}
      },
      "source": [
        "def logistic_regression(y, tx, initial_w, max_iters, gamma):"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dO4-cnmWxpn",
        "colab_type": "text"
      },
      "source": [
        "# **6. Regularized Logistic Regression**\n",
        "Regularized logistic regression using gradient descent\n",
        "or SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xEF8rZmeusk1",
        "colab": {}
      },
      "source": [
        "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUjkIrVVW2RX",
        "colab_type": "text"
      },
      "source": [
        "# **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJW6HstRWfuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(y, tx, w):\n",
        "    # Mean Squared Error\n",
        "    MSE = 1/(2*y.shape[0])*np.sum(np.square(y-np.dot(tx,w)))\n",
        "    return MSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc2EgK-TWfus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient(y, tx, w):\n",
        "    gradient = (-1/y.shape[0])*np.dot(tx.T,(y-np.dot(tx, w)))\n",
        "    return gradient"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}